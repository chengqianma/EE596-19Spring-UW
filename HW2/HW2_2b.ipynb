{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import timeit\n",
    "import load_cifar\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Hyper-perparmeter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data, val_labels = load_cifar.load_preprocessed_validation_batch()\n",
    "test_data, test_labels = load_cifar.load_pre_test_batch(10000)\n",
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "end = time.time()\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32, shape=[None, 3072])\n",
    "y_labels = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Neural Network Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-595ef7cb4fac>:1: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From f:\\anaconda\\envs\\envname\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "lay1 = tf.layers.dense(x_data, 500, activation=tf.nn.relu)\n",
    "lay2 = tf.layers.dense(lay1, 300, activation=tf.nn.relu)\n",
    "lay3 = tf.layers.dense(lay2, 200, activation=tf.nn.relu)\n",
    "output = tf.layers.dense(lay3, 10, activation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define cost andoptimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_labels, logits=output))\n",
    "opt = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "minimize = opt.minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(tf.nn.softmax(output),1),tf.argmax(y_labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32),name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training and testing</h1>\n",
    "<h2>1.Print out validation accuracy after each training poch</h2>\n",
    "<h2>2.Print out training time you spend on each epoch</h2>\n",
    "<h2>3.Print out testing accuracy in the end</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Accuracy:0.3530, Time: 2.548s\t\n",
      "Epoch 2, Validation Accuracy:0.4000, Time: 2.303s\t\n",
      "Epoch 3, Validation Accuracy:0.4196, Time: 2.305s\t\n",
      "Epoch 4, Validation Accuracy:0.4366, Time: 2.321s\t\n",
      "Epoch 5, Validation Accuracy:0.4450, Time: 2.313s\t\n",
      "Epoch 6, Validation Accuracy:0.4622, Time: 2.304s\t\n",
      "Epoch 7, Validation Accuracy:0.4656, Time: 2.307s\t\n",
      "Epoch 8, Validation Accuracy:0.4766, Time: 2.296s\t\n",
      "Epoch 9, Validation Accuracy:0.4854, Time: 2.297s\t\n",
      "Epoch 10, Validation Accuracy:0.4898, Time: 2.324s\t\n",
      "test set accuracy is: \t\n",
      "0.5003\n",
      "Epoch 11, Validation Accuracy:0.4898, Time: 2.318s\t\n",
      "Epoch 12, Validation Accuracy:0.4956, Time: 2.291s\t\n",
      "Epoch 13, Validation Accuracy:0.4948, Time: 2.305s\t\n",
      "Epoch 14, Validation Accuracy:0.4998, Time: 2.305s\t\n",
      "Epoch 15, Validation Accuracy:0.4990, Time: 2.319s\t\n",
      "Epoch 16, Validation Accuracy:0.4994, Time: 2.310s\t\n",
      "Epoch 17, Validation Accuracy:0.4998, Time: 2.289s\t\n",
      "Epoch 18, Validation Accuracy:0.5036, Time: 2.290s\t\n",
      "Epoch 19, Validation Accuracy:0.5046, Time: 2.283s\t\n",
      "Epoch 20, Validation Accuracy:0.5086, Time: 2.293s\t\n",
      "Epoch 21, Validation Accuracy:0.5118, Time: 2.287s\t\n",
      "Epoch 22, Validation Accuracy:0.5100, Time: 2.289s\t\n",
      "Epoch 23, Validation Accuracy:0.5088, Time: 2.282s\t\n",
      "Epoch 24, Validation Accuracy:0.5134, Time: 2.284s\t\n",
      "Epoch 25, Validation Accuracy:0.5120, Time: 2.305s\t\n",
      "Epoch 26, Validation Accuracy:0.5116, Time: 2.286s\t\n",
      "Epoch 27, Validation Accuracy:0.5148, Time: 2.280s\t\n",
      "Epoch 28, Validation Accuracy:0.5076, Time: 2.276s\t\n",
      "Epoch 29, Validation Accuracy:0.5126, Time: 2.345s\t\n",
      "Epoch 30, Validation Accuracy:0.5142, Time: 2.341s\t\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_epochs):\n",
    "        ts = time.time()\n",
    "        batch_num = 1\n",
    "        while batch_num < 6:\n",
    "            training_data = load_cifar.load_preprocessed_training_batch(batch_num, batch_size)\n",
    "            for data, labels in training_data:\n",
    "                f_dict = {x_data: data, y_labels: labels}\n",
    "                sess.run(minimize, feed_dict=f_dict)\n",
    "            batch_num += 1\n",
    "        te = time.time()\n",
    "        val_acc = sess.run(accuracy, feed_dict={x_data:val_data, y_labels:val_labels})\n",
    "        print(\"Epoch \" + str(i+1) + \", Validation Accuracy:{:.4f}\".format(val_acc)+ \", Time: {:.3f}s\\t\".format(te-ts))\n",
    "        if i == 9:\n",
    "            print('test set accuracy is: \\t')\n",
    "            test_acc = sess.run(accuracy, feed_dict={x_data:test_data, y_labels:test_labels})\n",
    "            print(test_acc)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Discussion</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, I use 9000 images as training set and 1000 images as validation set from the whole training set. Then I set up three fully connected layers, the hidden size is 500, 300 and 200. And I can get 50% test accuracy at 10 epoches sometimes. After 15 epoches training, the validation would be stable at 50%. So I think the network is so shallow that it is easy to reach the bottleneck. If we want to get much higer accuracy, we should design more hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
