{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extract MNIST data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",reshape=False,one_hot=True)\n",
    "tf.logging.set_verbosity(old_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Prepare training, validation and testing data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train           = mnist.train.images, mnist.train.labels\n",
    "x_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "x_test, y_test             = mnist.test.images, mnist.test.labels\n",
    "x_train_pad = np.pad(x_train, ((0,0), (2,2), (2,2), (0,0)), mode='constant', constant_values=0)\n",
    "x_validation_pad = np.pad(x_validation, ((0,0), (2,2), (2,2), (0,0)), mode='constant', constant_values=0)\n",
    "x_test_pad = np.pad(x_test, ((0,0), (2,2), (2,2), (0,0)), mode='constant', constant_values=0)\n",
    "\n",
    "def batches(data_x, data_y, batch_size):\n",
    "    i = 0  \n",
    "    while i * batch_size < data_x.shape[0]:\n",
    "        start = i * batch_size\n",
    "        end = i * batch_size + batch_size\n",
    "        yield (data_x[start:end], data_y[start:end])\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define hyperparameter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "lr = 0.001\n",
    "dropout_rate = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = tf.placeholder(tf.float32, shape=(None, 32, 32, 1))\n",
    "y_true = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "training = tf.placeholder_with_default(False, shape=(),name='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define LeNet-5</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-7baed9d8767b>:2: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From f:\\anaconda\\envs\\envname\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-7-7baed9d8767b>:5: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-7baed9d8767b>:17: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-7baed9d8767b>:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-7baed9d8767b>:21: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From f:\\anaconda\\envs\\envname\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "c1 = tf.layers.conv2d(x_in, filters=6, kernel_size=5, padding = 'SAME', activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "s1 = tf.layers.max_pooling2d(c1, pool_size=[2,2], strides=2)\n",
    "\n",
    "\n",
    "c2 = tf.layers.conv2d(s1, filters=16, kernel_size=5, activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "s2 = tf.layers.max_pooling2d(c2, pool_size=[2,2], strides=2)\n",
    "\n",
    "\n",
    "c3 = tf.layers.conv2d(s2, filters=120, kernel_size=5, activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "c3_flat = tf.layers.flatten(c3)\n",
    "\n",
    "\n",
    "d4 = tf.layers.dense(c3_flat, units=84, activation=tf.nn.sigmoid)\n",
    "\n",
    "d4_drop = tf.layers.dropout(d4,dropout_rate,training=training)\n",
    "\n",
    "out = tf.layers.dense(d4, units=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cost and optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=out))\n",
    "opt = tf.train.AdamOptimizer(lr)\n",
    "minimize = opt.minimize(cost)\n",
    "correct_pred = tf.equal(tf.argmax(tf.nn.softmax(out),1),tf.argmax(y_true,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32),name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training, validating, testing</h1>\n",
    "<h2>1. Print out validation accuracy after each training epoch</h2>\n",
    "<h2>2. Print out training time on each epoch</h2>\n",
    "<h2>3. Print out testing accuracy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Accuracy:0.9606, Time: 2.368s\t\n",
      "Epoch 1, Validation Accuracy:0.9822, Time: 2.297s\t\n",
      "Epoch 2, Validation Accuracy:0.9864, Time: 2.292s\t\n",
      "Epoch 3, Validation Accuracy:0.9878, Time: 2.301s\t\n",
      "Epoch 4, Validation Accuracy:0.9898, Time: 2.302s\t\n",
      "Epoch 5, Validation Accuracy:0.9890, Time: 2.323s\t\n",
      "Epoch 6, Validation Accuracy:0.9886, Time: 2.286s\t\n",
      "Epoch 7, Validation Accuracy:0.9914, Time: 2.296s\t\n",
      "Epoch 8, Validation Accuracy:0.9900, Time: 2.299s\t\n",
      "Epoch 9, Validation Accuracy:0.9908, Time: 2.299s\t\n",
      "Epoch 10, Validation Accuracy:0.9900, Time: 2.295s\t\n",
      "Epoch 11, Validation Accuracy:0.9916, Time: 2.295s\t\n",
      "Epoch 12, Validation Accuracy:0.9892, Time: 2.311s\t\n",
      "Epoch 13, Validation Accuracy:0.9910, Time: 2.318s\t\n",
      "Epoch 14, Validation Accuracy:0.9898, Time: 2.316s\t\n",
      "Epoch 15, Validation Accuracy:0.9904, Time: 2.350s\t\n",
      "Epoch 16, Validation Accuracy:0.9902, Time: 2.326s\t\n",
      "Epoch 17, Validation Accuracy:0.9920, Time: 2.301s\t\n",
      "Epoch 18, Validation Accuracy:0.9922, Time: 2.315s\t\n",
      "Epoch 19, Validation Accuracy:0.9898, Time: 2.397s\t\n",
      "Epoch 20, Validation Accuracy:0.9900, Time: 2.291s\t\n",
      "Epoch 21, Validation Accuracy:0.9894, Time: 2.298s\t\n",
      "Epoch 22, Validation Accuracy:0.9916, Time: 2.337s\t\n",
      "Epoch 23, Validation Accuracy:0.9898, Time: 2.318s\t\n",
      "Epoch 24, Validation Accuracy:0.9916, Time: 2.300s\t\n",
      "Epoch 25, Validation Accuracy:0.9908, Time: 2.294s\t\n",
      "Epoch 26, Validation Accuracy:0.9908, Time: 2.293s\t\n",
      "Epoch 27, Validation Accuracy:0.9908, Time: 2.289s\t\n",
      "Epoch 28, Validation Accuracy:0.9918, Time: 2.293s\t\n",
      "Epoch 29, Validation Accuracy:0.9920, Time: 2.291s\t\n",
      "Epoch 30, Validation Accuracy:0.9914, Time: 2.295s\t\n",
      "Epoch 31, Validation Accuracy:0.9918, Time: 2.313s\t\n",
      "Epoch 32, Validation Accuracy:0.9916, Time: 2.318s\t\n",
      "Epoch 33, Validation Accuracy:0.9912, Time: 2.296s\t\n",
      "Epoch 34, Validation Accuracy:0.9916, Time: 2.291s\t\n",
      "Epoch 35, Validation Accuracy:0.9912, Time: 2.292s\t\n",
      "Epoch 36, Validation Accuracy:0.9912, Time: 2.291s\t\n",
      "Epoch 37, Validation Accuracy:0.9910, Time: 2.304s\t\n",
      "Epoch 38, Validation Accuracy:0.9918, Time: 2.302s\t\n",
      "Epoch 39, Validation Accuracy:0.9924, Time: 2.297s\t\n",
      "Epoch 40, Validation Accuracy:0.9932, Time: 2.292s\t\n",
      "Epoch 41, Validation Accuracy:0.9914, Time: 2.293s\t\n",
      "Epoch 42, Validation Accuracy:0.9922, Time: 2.299s\t\n",
      "Epoch 43, Validation Accuracy:0.9934, Time: 2.295s\t\n",
      "Epoch 44, Validation Accuracy:0.9928, Time: 2.299s\t\n",
      "Epoch 45, Validation Accuracy:0.9924, Time: 2.296s\t\n",
      "Epoch 46, Validation Accuracy:0.9926, Time: 2.294s\t\n",
      "Epoch 47, Validation Accuracy:0.9924, Time: 2.294s\t\n",
      "Epoch 48, Validation Accuracy:0.9926, Time: 2.297s\t\n",
      "Epoch 49, Validation Accuracy:0.9926, Time: 2.293s\t\n",
      "Test_Accuarcy\n",
      "0.9932\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)   \n",
    "    for i in range(num_epochs):\n",
    "        ts = time.time()\n",
    "        training_batches = batches(x_train_pad, y_train, batch_size)\n",
    "        for x_data, y_labels in training_batches:\n",
    "            f_dict = {x_in: x_data, y_true: y_labels, training: True}\n",
    "            sess.run(minimize, feed_dict=f_dict)\n",
    "        te = time.time()\n",
    "        val_acc = sess.run(accuracy, feed_dict={x_in:x_validation_pad, y_true:y_validation})\n",
    "        print(\"Epoch \" + str(i) + \", Validation Accuracy:{:.4f}\".format(val_acc)+ \", Time: {:.3f}s\\t\".format(te-ts))\n",
    "       \n",
    "    test_acc = sess.run(accuracy, feed_dict={x_in:x_test_pad, y_true:y_test})\n",
    "    print('Test_Accuarcy')\n",
    "    print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
