{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import load_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "val_data, val_labels = load_cifar.load_preprocessed_validation_batch()\n",
    "test_data, test_labels = load_cifar.load_pre_test_batch(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hyperparameter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))\n",
    "y_labels = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "training = tf.placeholder_with_default(False, shape=(),name='training')\n",
    "#regularizer = tf.contrib.layers.l2_regularizer(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>LeNet-5</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\anaconda\\envs\\envname\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-5-89ebc65eede0>:3: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-89ebc65eede0>:6: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-89ebc65eede0>:7: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-89ebc65eede0>:14: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.average_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-89ebc65eede0>:21: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-89ebc65eede0>:24: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-89ebc65eede0>:25: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From f:\\anaconda\\envs\\envname\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# c1: convolution2d\n",
    "conv1_b = tf.Variable(tf.zeros(6))\n",
    "conv1 = tf.layers.conv2d(x_data, filters=6, kernel_size=5, activation = tf.nn.relu,padding = 'VALID')\n",
    "#conv1_bn_act = tf.nn.relu(conv1_bn)\n",
    "conv1_out = conv1 + conv1_b\n",
    "pool1 = tf.layers.max_pooling2d(conv1_out, pool_size=2, strides=2,padding = 'VALID')\n",
    "pool1_bn = tf.layers.batch_normalization(pool1)\n",
    "\n",
    "# c2: convolution 2d size (5,5, 10)\n",
    "conv2_b = tf.Variable(tf.zeros(16))\n",
    "conv2 = tf.layers.conv2d(pool1_bn, filters=16, kernel_size=5,activation = tf.nn.relu,padding = 'VALID')\n",
    "#conv2_bn_act = tf.nn.relu(conv2_bn)\n",
    "conv2_out = conv2 + conv2_b\n",
    "pool2 = tf.layers.average_pooling2d(conv2_out, pool_size=2, strides=2,padding = 'VALID')\n",
    "pool2_bn = tf.layers.batch_normalization(pool2)\n",
    "\n",
    "# c4: 1x1 conv layer\n",
    "conv3 = tf.layers.conv2d(pool2_bn, filters=120, kernel_size=5,activation = tf.nn.relu,padding = 'VALID')\n",
    "conv3_bn = tf.layers.batch_normalization(conv3)\n",
    "conv3_flat = tf.layers.flatten(conv3_bn)\n",
    "\n",
    "\n",
    "fc = tf.layers.dense(conv3_flat, units=84, activation = tf.nn.relu)\n",
    "fc_drop = tf.layers.dropout(fc,dropout_rate,training=training)\n",
    "fc_bn = tf.layers.batch_normalization(fc_drop)\n",
    "#fc_bn_act = tf.nn.relu(fc_bn)\n",
    "out = tf.layers.dense(fc_bn, units=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cost and Optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_labels, logits=out))\n",
    "#l2_loss = tf.losses.get_regularization_loss()\n",
    "#loss = loss + l2_loss\n",
    "opt = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "minimize = opt.minimize(loss)\n",
    "\n",
    "# compare prediction accuracy \n",
    "correct_pred = tf.equal(tf.argmax(tf.nn.softmax(out),1),tf.argmax(y_labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32),name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training, validation and testing</h1>\n",
    "<h2>Train your model only 10 epochs.</h2>\n",
    "<h2>1.Print out validation accuracy after each training epoch</h2>\n",
    "<h2>2.Print out training time for each training epoch</h2>\n",
    "<h2>3.Print out testing accuracy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Accuracy:0.4302, Time: 7.066s\t\n",
      "Epoch 2, Validation Accuracy:0.4642, Time: 5.840s\t\n",
      "Epoch 3, Validation Accuracy:0.5098, Time: 5.799s\t\n",
      "Epoch 4, Validation Accuracy:0.5340, Time: 5.743s\t\n",
      "Epoch 5, Validation Accuracy:0.5398, Time: 5.694s\t\n",
      "Epoch 6, Validation Accuracy:0.5484, Time: 5.680s\t\n",
      "Epoch 7, Validation Accuracy:0.5592, Time: 5.685s\t\n",
      "Epoch 8, Validation Accuracy:0.5670, Time: 5.677s\t\n",
      "Epoch 9, Validation Accuracy:0.5660, Time: 5.696s\t\n",
      "Epoch 10, Validation Accuracy:0.5716, Time: 5.685s\t\n",
      "test set accuracy is: \t\n",
      "0.573\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_epochs):\n",
    "        ts = time.time()\n",
    "        batch_num = 1\n",
    "        while batch_num < 6:\n",
    "            #print('Training for Batch: \\t' + str(batch_num))\n",
    "            training_data = load_cifar.load_preprocessed_training_batch(batch_num, batch_size)\n",
    "            for data, labels in training_data:\n",
    "                f_dict = {x_data: np.reshape(data, (-1, 32, 32, 3)), y_labels: labels, training: True}\n",
    "                sess.run(minimize, feed_dict=f_dict)\n",
    "            batch_num += 1\n",
    "        te = time.time()\n",
    "        val_acc = sess.run(accuracy, feed_dict={x_data:np.reshape(val_data, (-1, 32, 32, 3)), y_labels:val_labels})\n",
    "        print(\"Epoch \" + str(i+1) + \", Validation Accuracy:{:.4f}\".format(val_acc)+ \", Time: {:.3f}s\\t\".format(te-ts))\n",
    "        \n",
    "    print('test set accuracy is: \\t')\n",
    "    test_acc = sess.run(accuracy, feed_dict={x_data:np.reshape(test_data, (-1, 32, 32, 3)), y_labels:test_labels})\n",
    "    print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
