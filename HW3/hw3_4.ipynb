{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "from text_utils import TextLoader\n",
    "import text_utils as txt\n",
    "from tensorflow.contrib import rnn\n",
    "from char_rnn_model import Model\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.logging.set_verbosity(old_v)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]='3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define directories, hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dire = ''\n",
    "batch_size = 32\n",
    "total_batches = 30000\n",
    "num_seq = 32 \n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data using TextLoader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = TextLoader(dire,num_seq, batch_size)\n",
    "train_dataset, char_dataset = load_data.load_processed_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train = txt.batch(train_dataset,num_seq,batch_size)\n",
    "NN = Model(batch_size,num_seq,learning_rate,load_data.vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1000/30000  Loss: 2.5541 \n",
      "Batch: 2000/30000  Loss: 2.4633 \n",
      "Batch: 3000/30000  Loss: 2.4366 \n",
      "Batch: 4000/30000  Loss: 2.2784 \n",
      "Batch: 5000/30000  Loss: 2.2489 \n",
      "Batch: 6000/30000  Loss: 2.1545 \n",
      "Batch: 7000/30000  Loss: 2.1599 \n",
      "Batch: 8000/30000  Loss: 2.1011 \n",
      "Batch: 9000/30000  Loss: 2.1028 \n",
      "Batch: 10000/30000  Loss: 2.0965 \n",
      "Batch: 11000/30000  Loss: 2.1075 \n",
      "Batch: 12000/30000  Loss: 2.1148 \n",
      "Batch: 13000/30000  Loss: 2.0643 \n",
      "Batch: 14000/30000  Loss: 2.0857 \n",
      "Batch: 15000/30000  Loss: 2.0309 \n",
      "Batch: 16000/30000  Loss: 2.0130 \n",
      "Batch: 17000/30000  Loss: 2.0968 \n",
      "Batch: 18000/30000  Loss: 2.0141 \n",
      "Batch: 19000/30000  Loss: 1.9686 \n",
      "Batch: 20000/30000  Loss: 2.0165 \n",
      "Batch: 21000/30000  Loss: 2.0491 \n",
      "Batch: 22000/30000  Loss: 1.9551 \n",
      "Batch: 23000/30000  Loss: 2.0441 \n",
      "Batch: 24000/30000  Loss: 2.0433 \n",
      "Batch: 25000/30000  Loss: 1.9292 \n",
      "Batch: 26000/30000  Loss: 1.9333 \n",
      "Batch: 27000/30000  Loss: 1.9729 \n",
      "Batch: 28000/30000  Loss: 1.9878 \n",
      "Batch: 29000/30000  Loss: 2.1209 \n",
      "Batch: 30000/30000  Loss: 1.9977 \n"
     ]
    }
   ],
   "source": [
    "NN.train(total_batches, batch_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from char_rnn/model-30000\n",
      "Restored from: char_rnn/model-30000\n",
      "I see this heart of all this courtesinal seatives:And to me, and a cell thee that think the warred of the moster all all heavens and a sisters and mare mine than the taken sir, that he said of the honour.PARSIUS:I have merces and hards there, shall they stay that to these stractest are that wouse to me to mare the heavine have the parts that hil high stopp and heard, see this honour of my cires.TARSIUS:With surfer's son.SETRONGES:If that his prease the sing out what he's so be sit out of thy loves; what is a pardon and that she's will,This is no merery; sir; to the canting on his companience,I have speak the pourses of my heart to him, son as he hast to straight to the sige.ANTONIO:Why, many that she, sir, she sean her shint is not.PRENSONE:And thou didst hill that have the thousent should holr your soldome. By this here,And his sonsel are a sondy assaints our fool arminias.ANTONIO:And what went ship to make his pretervicate thinks. I with him would needs and spalied, and they are tange\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.latest_checkpoint('char_rnn/')\n",
    "NN_test = Model(batch_size, num_seq,learning_rate,vocab_size=load_data.vocab_size, training=False)\n",
    "NN_test.load(checkpoint)\n",
    "n = 1000\n",
    "result = model.sample(char_dataset, load_data.vocab, n)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
